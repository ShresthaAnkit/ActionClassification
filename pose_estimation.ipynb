{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Pose and Drawing utilities\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASET_DIR = 'Single_person_violent'\n",
    "DATASET_DIR = 'Final_Dataset'\n",
    "CLASSES_LIST = [\"Kicking\",\"Punching\",\"Block\",\"Idle\"]\n",
    "OUTPUT_DIR = 'Output'\n",
    "custom_headers = ['Frame Number', 'x','y','z','Visibility']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert mediapipe landmarks into proper format for storing into a CSV file\n",
    "def write_landmarks_to_csv(landmarks, frame_number, csv_data):\n",
    "    #print(f\"Landmark coordinates for frame {frame_number}:\")\n",
    "    for idx, landmark in enumerate(landmarks):\n",
    "        #print(f\"{mp_pose.PoseLandmark(idx).name}: (x: {landmark.x}, y: {landmark.y}, z: {landmark.z})\")\n",
    "        csv_data.append([frame_number, landmark.x, landmark.y, landmark.z, landmark.visibility])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a video into landmarks using mediapipe\n",
    "def convert_video_to_landmark_csv(video_path):\n",
    "    frame_number = 0\n",
    "    csv_data = []\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():            \n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame_number += 1\n",
    "            # Convert the image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            # Perform pose detection\n",
    "            results = pose.process(image)\n",
    "\n",
    "            # Convert the image back to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Draw the pose annotation on the image\n",
    "            if results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            # Add the landmark coordinates to the list and print them\n",
    "            write_landmarks_to_csv(results.pose_landmarks.landmark, frame_number, csv_data)   \n",
    "    cap.release() \n",
    "\n",
    "    # Extract file and class names from the video path\n",
    "    file_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    class_name = os.path.basename(os.path.dirname(video_path))\n",
    "\n",
    "    output_file = os.path.join(output_file_dir, f'{file_name}.csv')\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    output_file_dir = os.path.join(OUTPUT_DIR, class_name)        \n",
    "    os.makedirs(output_file_dir, exist_ok=True)  \n",
    "\n",
    "    with open(f'{output_file}.csv', mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write each row of the 2D array\n",
    "        for row in csv_data:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all videos in the given CLASSES_LIST into landmark csv files\n",
    "def create_dataset(CLASSES_LIST):\n",
    "    print('List: ',CLASSES_LIST)\n",
    "    for class_name in CLASSES_LIST:\n",
    "        print(f\"Extracting data from {class_name}\")\n",
    "        # Get list of videos for each class\n",
    "        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n",
    "        for file_name in files_list:\n",
    "            # Get the complete video path.\n",
    "            video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
    "            convert_video_to_landmark_csv(video_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequence from a CSV file for making a single dataframe\n",
    "def createSequence(csv_path, label):\n",
    "    # Define custom headers for the CSV file\n",
    "    custom_headers = ['Frame Number', 'x', 'y', 'z', 'Visibility']\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    data = pd.read_csv(csv_path, header=None, names=custom_headers)\n",
    "    \n",
    "    # Initialize the sequence with the label\n",
    "    sequence = [label]\n",
    "    \n",
    "    # Group the data by 'Frame Number' and collect frame data\n",
    "    grouped = data.groupby('Frame Number')[['x', 'y', 'z', 'Visibility']].apply(lambda x: x.values.tolist())\n",
    "    \n",
    "    # Extend the sequence with the grouped frame data\n",
    "    sequence.extend(grouped.tolist())\n",
    "    \n",
    "    return sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from CSV and append to processed_df\n",
    "sequence = createSequence('output.csv','Kicking')\n",
    "processed_df = pd.DataFrame([sequence])\n",
    "#processed_df2 = processed_df.append(pd.DataFrame(frame, columns=['x', 'y', 'z', 'Visibility']), ignore_index=True)\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('output.csv',header=None,names=custom_headers)\n",
    "print(dat.groupby('FrameNumber')['x'].apply(lambda x: x.tolist()).iloc[:1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the CSV files of the given CLASSES_LIST\n",
    "def getAllCSV(CLASSES_LIST):\n",
    "    files = {}\n",
    "    for class_name in CLASSES_LIST:        \n",
    "        # Get list of csv files for each class\n",
    "        files_list = os.listdir(os.path.join(OUTPUT_DIR, class_name))\n",
    "        for file_name in files_list:\n",
    "            # Get the complete csv path.\n",
    "            files.setdefault(class_name,[]).append(os.path.join(OUTPUT_DIR, class_name, file_name))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all the sequences into a single dataframe and return it\n",
    "def createDataframe():\n",
    "    df_array = []    \n",
    "    for class_name in CLASSES_LIST:        \n",
    "        # Get list of csv files for each class\n",
    "        files_list = os.listdir(os.path.join(OUTPUT_DIR, class_name))\n",
    "        for file_name in files_list:\n",
    "            # Get the complete csv path.\n",
    "            csv_file_path = os.path.join(OUTPUT_DIR, class_name, file_name)            \n",
    "            df_array.append(createSequence(csv_file_path,class_name))\n",
    "    return pd.DataFrame(df_array)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and standard deviation of z values (depth values)\n",
    "def calculateZParamsForNormalization(CLASSES_LIST,csv_files):\n",
    "    custom_headers = ['FrameNumber','x','y','z','Visibility']\n",
    "    z_values = []\n",
    "    for key in CLASSES_LIST:\n",
    "        for file in csv_files[key]:\n",
    "            df = pd.read_csv(file,header=None,names=custom_headers)\n",
    "            z_values.extend(df['z'].values)\n",
    "    z_mean = np.mean(z_values)\n",
    "    z_std = np.std(z_values)\n",
    "    return z_mean, z_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the min and max of z values (depth values)\n",
    "def calculateZMinMaxForNormalization(CLASSES_LIST,csv_files):\n",
    "    custom_headers = ['FrameNumber','x','y','z','Visibility']\n",
    "    z_values = []\n",
    "    for key in CLASSES_LIST:\n",
    "        for file in csv_files[key]:\n",
    "            df = pd.read_csv(file,header=None,names=custom_headers)\n",
    "            z_values.extend(df['z'].values)\n",
    "    z_min = np.min(z_values)\n",
    "    z_max = np.max(z_values)\n",
    "    return z_min, z_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all the z values (depth values) in the CSV files\n",
    "def normalizeZValuesInCSV(files,z_min, z_max):\n",
    "    custom_headers = ['FrameNumber','x','y','z','Visibility']\n",
    "    for key in files:\n",
    "        for file in files[key]:\n",
    "            df = pd.read_csv(file,header=None,names=custom_headers)\n",
    "            # Normalize the 'z' column using Min-Max scaling\n",
    "            df['z'] = (df['z'] - z_min) / (z_max - z_min)\n",
    "            df.to_csv(file, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset(CLASSES_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = createDataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df[complete_df.iloc[:,0] == 'Punching'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = getAllCSV(CLASSES_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('output.csv',header=None,names=custom_headers)\n",
    "arr = []\n",
    "arr.extend(df2['z'].values)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean, z_std = calculateZParamsForNormalization(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_min, z_max = calculateZMinMaxForNormalization(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.10812381639618134, 0.44725407070063944)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_mean, z_std\n",
    "#(-0.10812381639618134, 0.44725407070063944)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_min, z_max\n",
    "#(-1.6407425403594973, 1.754867672920227)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizeZValuesInCSV(files,z_min, z_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
