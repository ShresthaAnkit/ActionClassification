{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Ankit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Pose and Drawing utilities\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASET_DIR = 'Single_person_violent'\n",
    "DATASET_DIR = 'Final_Dataset'\n",
    "CLASSES_LIST = [\"Kicking\",\"Punching\",\"Block\",\"Idle\"]\n",
    "OUTPUT_DIR = 'Output'\n",
    "custom_headers = ['Frame Number', 'x','y','z','Visibility']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert mediapipe landmarks into proper format for storing into a CSV file\n",
    "def write_landmarks_to_csv(landmarks, frame_number, csv_data):\n",
    "    #print(f\"Landmark coordinates for frame {frame_number}:\")\n",
    "    for idx, landmark in enumerate(landmarks):\n",
    "        #print(f\"{mp_pose.PoseLandmark(idx).name}: (x: {landmark.x}, y: {landmark.y}, z: {landmark.z})\")\n",
    "        csv_data.append([frame_number, landmark.x, landmark.y, landmark.z, landmark.visibility])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a video into landmarks using mediapipe\n",
    "def convert_video_to_landmark_csv(video_path):\n",
    "    frame_number = 0\n",
    "    csv_data = []\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():            \n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame_number += 1\n",
    "            # Convert the image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            # Perform pose detection\n",
    "            results = pose.process(image)\n",
    "\n",
    "            # Convert the image back to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Draw the pose annotation on the image\n",
    "            if results.pose_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            # Add the landmark coordinates to the list and print them\n",
    "            write_landmarks_to_csv(results.pose_landmarks.landmark, frame_number, csv_data)   \n",
    "    cap.release() \n",
    "\n",
    "    # Extract file and class names from the video path\n",
    "    file_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    class_name = os.path.basename(os.path.dirname(video_path))\n",
    "\n",
    "    \n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    output_file_dir = os.path.join(OUTPUT_DIR, class_name)        \n",
    "    os.makedirs(output_file_dir, exist_ok=True)  \n",
    "\n",
    "    output_file = os.path.join(output_file_dir, f'{file_name}.csv')\n",
    "\n",
    "    with open(f'{output_file}.csv', mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write each row of the 2D array\n",
    "        for row in csv_data:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all videos in the given CLASSES_LIST into landmark csv files\n",
    "def create_dataset(CLASSES_LIST):\n",
    "    print('List: ',CLASSES_LIST)\n",
    "    for class_name in CLASSES_LIST:\n",
    "        print(f\"Extracting data from {class_name}\")\n",
    "        # Get list of videos for each class\n",
    "        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n",
    "        for file_name in files_list:\n",
    "            # Get the complete video path.\n",
    "            video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
    "            convert_video_to_landmark_csv(video_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequence from a CSV file for making a single dataframe\n",
    "def createSequence(csv_path, label):\n",
    "    # Define custom headers for the CSV file\n",
    "    custom_headers = ['Frame Number', 'x', 'y', 'z', 'Visibility']\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    data = pd.read_csv(csv_path, header=None, names=custom_headers)\n",
    "    \n",
    "    # Initialize the sequence with the label\n",
    "    sequence = [label]\n",
    "    \n",
    "    # Group the data by 'Frame Number' and collect frame data\n",
    "    grouped = data.groupby('Frame Number')[['x', 'y', 'z', 'Visibility']].apply(lambda x: x.values.tolist())\n",
    "    \n",
    "    # Extend the sequence with the grouped frame data\n",
    "    sequence.extend(grouped.tolist())\n",
    "    \n",
    "    return sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kicking</td>\n",
       "      <td>[[0.4208270311355591, 0.2813926935195923, -0.5...</td>\n",
       "      <td>[[0.4226616024971008, 0.2830023467540741, -0.4...</td>\n",
       "      <td>[[0.422335147857666, 0.2832168936729431, -0.48...</td>\n",
       "      <td>[[0.4239648282527923, 0.2812423706054687, -0.2...</td>\n",
       "      <td>[[0.4259682595729828, 0.2790455818176269, -0.2...</td>\n",
       "      <td>[[0.424310564994812, 0.2764437794685364, -0.26...</td>\n",
       "      <td>[[0.424225777387619, 0.2755632400512695, 0.049...</td>\n",
       "      <td>[[0.4241669476032257, 0.2759043276309967, -0.1...</td>\n",
       "      <td>[[0.4190621674060821, 0.2758240699768066, -0.0...</td>\n",
       "      <td>...</td>\n",
       "      <td>[[0.4902646839618683, 0.266271561384201, -0.52...</td>\n",
       "      <td>[[0.4924321174621582, 0.2656450271606445, -0.5...</td>\n",
       "      <td>[[0.4942595660686493, 0.2644723653793335, -0.5...</td>\n",
       "      <td>[[0.4932672381401062, 0.2639179527759552, -0.5...</td>\n",
       "      <td>[[0.4929601550102234, 0.264041006565094, -0.53...</td>\n",
       "      <td>[[0.4959222972393036, 0.2640158534049988, -0.5...</td>\n",
       "      <td>[[0.5004463791847229, 0.2640080451965332, -0.5...</td>\n",
       "      <td>[[0.5007750391960144, 0.2638412415981293, -0.4...</td>\n",
       "      <td>[[0.4997018575668335, 0.2627485990524292, -0.4...</td>\n",
       "      <td>[[0.4992328286170959, 0.262261152267456, -0.44...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0                                                  1   \\\n",
       "0  Kicking  [[0.4208270311355591, 0.2813926935195923, -0.5...   \n",
       "\n",
       "                                                  2   \\\n",
       "0  [[0.4226616024971008, 0.2830023467540741, -0.4...   \n",
       "\n",
       "                                                  3   \\\n",
       "0  [[0.422335147857666, 0.2832168936729431, -0.48...   \n",
       "\n",
       "                                                  4   \\\n",
       "0  [[0.4239648282527923, 0.2812423706054687, -0.2...   \n",
       "\n",
       "                                                  5   \\\n",
       "0  [[0.4259682595729828, 0.2790455818176269, -0.2...   \n",
       "\n",
       "                                                  6   \\\n",
       "0  [[0.424310564994812, 0.2764437794685364, -0.26...   \n",
       "\n",
       "                                                  7   \\\n",
       "0  [[0.424225777387619, 0.2755632400512695, 0.049...   \n",
       "\n",
       "                                                  8   \\\n",
       "0  [[0.4241669476032257, 0.2759043276309967, -0.1...   \n",
       "\n",
       "                                                  9   ...  \\\n",
       "0  [[0.4190621674060821, 0.2758240699768066, -0.0...  ...   \n",
       "\n",
       "                                                  28  \\\n",
       "0  [[0.4902646839618683, 0.266271561384201, -0.52...   \n",
       "\n",
       "                                                  29  \\\n",
       "0  [[0.4924321174621582, 0.2656450271606445, -0.5...   \n",
       "\n",
       "                                                  30  \\\n",
       "0  [[0.4942595660686493, 0.2644723653793335, -0.5...   \n",
       "\n",
       "                                                  31  \\\n",
       "0  [[0.4932672381401062, 0.2639179527759552, -0.5...   \n",
       "\n",
       "                                                  32  \\\n",
       "0  [[0.4929601550102234, 0.264041006565094, -0.53...   \n",
       "\n",
       "                                                  33  \\\n",
       "0  [[0.4959222972393036, 0.2640158534049988, -0.5...   \n",
       "\n",
       "                                                  34  \\\n",
       "0  [[0.5004463791847229, 0.2640080451965332, -0.5...   \n",
       "\n",
       "                                                  35  \\\n",
       "0  [[0.5007750391960144, 0.2638412415981293, -0.4...   \n",
       "\n",
       "                                                  36  \\\n",
       "0  [[0.4997018575668335, 0.2627485990524292, -0.4...   \n",
       "\n",
       "                                                  37  \n",
       "0  [[0.4992328286170959, 0.262261152267456, -0.44...  \n",
       "\n",
       "[1 rows x 38 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from CSV and append to processed_df\n",
    "sequence = createSequence('output.csv','Kicking')\n",
    "processed_df = pd.DataFrame([sequence])\n",
    "#processed_df2 = processed_df.append(pd.DataFrame(frame, columns=['x', 'y', 'z', 'Visibility']), ignore_index=True)\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = pd.read_csv('output.csv',header=None,names=custom_headers)\n",
    "dat['Frame Number'].tail(1).values[0]\n",
    "#print(dat.groupby('FrameNumber')['x'].apply(lambda x: x.tolist()).iloc[:1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the CSV files of the given CLASSES_LIST\n",
    "def getAllCSV(CLASSES_LIST):\n",
    "    files = {}\n",
    "    for class_name in CLASSES_LIST:        \n",
    "        # Get list of csv files for each class\n",
    "        files_list = os.listdir(os.path.join(OUTPUT_DIR, class_name))\n",
    "        for file_name in files_list:\n",
    "            # Get the complete csv path.\n",
    "            files.setdefault(class_name,[]).append(os.path.join(OUTPUT_DIR, class_name, file_name))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all the sequences into a single dataframe and return it\n",
    "def createDataframe():\n",
    "    df_array = []    \n",
    "    for class_name in CLASSES_LIST:        \n",
    "        # Get list of csv files for each class\n",
    "        files_list = os.listdir(os.path.join(OUTPUT_DIR, class_name))\n",
    "        for file_name in files_list:\n",
    "            # Get the complete csv path.\n",
    "            csv_file_path = os.path.join(OUTPUT_DIR, class_name, file_name)            \n",
    "            df_array.append(createSequence(csv_file_path,class_name))\n",
    "    return pd.DataFrame(df_array)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and standard deviation of z values (depth values)\n",
    "def calculateZParamsForNormalization(CLASSES_LIST,csv_files):\n",
    "    custom_headers = ['FrameNumber','x','y','z','Visibility']\n",
    "    z_values = []\n",
    "    for key in CLASSES_LIST:\n",
    "        for file in csv_files[key]:\n",
    "            df = pd.read_csv(file,header=None,names=custom_headers)\n",
    "            z_values.extend(df['z'].values)\n",
    "    z_mean = np.mean(z_values)\n",
    "    z_std = np.std(z_values)\n",
    "    return z_mean, z_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the min and max of z values (depth values)\n",
    "def calculateZMinMaxForNormalization(CLASSES_LIST,csv_files):\n",
    "    custom_headers = ['FrameNumber','x','y','z','Visibility']\n",
    "    z_values = []\n",
    "    for key in CLASSES_LIST:\n",
    "        for file in csv_files[key]:\n",
    "            df = pd.read_csv(file,header=None,names=custom_headers)\n",
    "            z_values.extend(df['z'].values)\n",
    "    z_min = np.min(z_values)\n",
    "    z_max = np.max(z_values)\n",
    "    return z_min, z_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all the z values (depth values) in the CSV files\n",
    "def normalizeZValuesInCSV(CLASSES_LIST):\n",
    "    custom_headers = ['FrameNumber','x','y','z','Visibility']\n",
    "    files = getAllCSV(CLASSES_LIST)\n",
    "    z_min, z_max = calculateZMinMaxForNormalization(CLASSES_LIST,files)\n",
    "    for key in files:\n",
    "        for file in files[key]:\n",
    "            df = pd.read_csv(file,header=None,names=custom_headers)\n",
    "            # Normalize the 'z' column using Min-Max scaling\n",
    "            df['z'] = (df['z'] - z_min) / (z_max - z_min)\n",
    "            df.to_csv(file, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findHighestFrameNumber(CLASSES_LIST):\n",
    "    highest_frame_number = 0\n",
    "    custom_headers = ['FrameNumber','x','y','z','Visibility']\n",
    "    files = getAllCSV(CLASSES_LIST)        \n",
    "    highest_frame_video = ''\n",
    "    for key in files:        \n",
    "        for file in files[key]:            \n",
    "            df = pd.read_csv(file,header=None,names=custom_headers)\n",
    "            current_frame_number = df['FrameNumber'].tail(1).values[0]\n",
    "            if  current_frame_number > highest_frame_number:\n",
    "                highest_frame_number = current_frame_number  \n",
    "                highest_frame_video  = file      \n",
    "    return highest_frame_number,highest_frame_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFramesHigherThanX(CLASSES_LIST,X):    \n",
    "    custom_headers = ['FrameNumber','x','y','z','Visibility']\n",
    "    files = getAllCSV(CLASSES_LIST)        \n",
    "    high_frame_videos = []\n",
    "    for key in files:        \n",
    "        for file in files[key]:            \n",
    "            df = pd.read_csv(file,header=None,names=custom_headers)\n",
    "            current_frame_number = df['FrameNumber'].tail(1).values[0]\n",
    "            if  current_frame_number > X:\n",
    "                high_frame_videos.append((file,current_frame_number))\n",
    "    return high_frame_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List:  ['Kicking', 'Punching', 'Block', 'Idle']\n",
      "Extracting data from Kicking\n",
      "Extracting data from Punching\n",
      "Extracting data from Block\n",
      "Extracting data from Idle\n"
     ]
    }
   ],
   "source": [
    "create_dataset(CLASSES_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizeZValuesInCSV(CLASSES_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Output\\\\Kicking\\\\kick_left13.csv', 130),\n",
       " ('Output\\\\Kicking\\\\kick_right2.csv', 102),\n",
       " ('Output\\\\Block\\\\block6.csv', 110),\n",
       " ('Output\\\\Idle\\\\idle16.csv', 216),\n",
       " ('Output\\\\Idle\\\\idle17.csv', 210),\n",
       " ('Output\\\\Idle\\\\idle4.csv', 107)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_frame_videos = findFramesHigherThanX(CLASSES_LIST,100)\n",
    "high_frame_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "highestFrameNumber, highestFrameVideo = findHighestFrameNumber(CLASSES_LIST)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216, 'Output\\\\Idle\\\\idle16.csv')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highestFrameNumber, highestFrameVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = createDataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df[complete_df.iloc[:,0] == 'Punching'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = getAllCSV(CLASSES_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('output.csv',header=None,names=custom_headers)\n",
    "arr = []\n",
    "arr.extend(df2['z'].values)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean, z_std = calculateZParamsForNormalization(CLASSES_LIST,files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_min, z_max = calculateZMinMaxForNormalization(CLASSES_LIST,files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5545347004295016, 0.09994274934490296)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_mean, z_std\n",
    "#(-0.10812381639618134, 0.44725407070063944)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_min, z_max\n",
    "#(-1.6407425403594973, 1.754867672920227)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed kick16a.csv.csv to kick16a.csv\n",
      "Renamed kick16b.csv.csv to kick16b.csv\n",
      "Renamed kick17a.csv.csv to kick17a.csv\n",
      "Renamed kick17b.csv.csv to kick17b.csv\n",
      "Renamed kick18a.csv.csv to kick18a.csv\n",
      "Renamed kick18b.csv.csv to kick18b.csv\n",
      "Renamed kick19a.csv.csv to kick19a.csv\n",
      "Renamed kick19b.csv.csv to kick19b.csv\n",
      "Renamed kick20a.csv.csv to kick20a.csv\n",
      "Renamed kick20b.csv.csv to kick20b.csv\n",
      "Renamed kick21a.csv.csv to kick21a.csv\n",
      "Renamed kick21b.csv.csv to kick21b.csv\n",
      "Renamed kick22a.csv.csv to kick22a.csv\n",
      "Renamed kick22b.csv.csv to kick22b.csv\n",
      "Renamed kick23a.csv.csv to kick23a.csv\n",
      "Renamed kick23b.csv.csv to kick23b.csv\n",
      "Renamed kick24a.csv.csv to kick24a.csv\n",
      "Renamed kick24b.csv.csv to kick24b.csv\n",
      "Renamed kick25a.csv.csv to kick25a.csv\n",
      "Renamed kick25b.csv.csv to kick25b.csv\n",
      "Renamed kick26a.csv.csv to kick26a.csv\n",
      "Renamed kick26b.csv.csv to kick26b.csv\n",
      "Renamed kick27a.csv.csv to kick27a.csv\n",
      "Renamed kick27b.csv.csv to kick27b.csv\n",
      "Renamed kick28a.csv.csv to kick28a.csv\n",
      "Renamed kick28b.csv.csv to kick28b.csv\n",
      "Renamed kick29a.csv.csv to kick29a.csv\n",
      "Renamed kick29b.csv.csv to kick29b.csv\n",
      "Renamed kick30a.csv.csv to kick30a.csv\n",
      "Renamed kick30b.csv.csv to kick30b.csv\n",
      "Renamed kick_left1.csv.csv to kick_left1.csv\n",
      "Renamed kick_left10.csv.csv to kick_left10.csv\n",
      "Renamed kick_left11.csv.csv to kick_left11.csv\n",
      "Renamed kick_left12.csv.csv to kick_left12.csv\n",
      "Renamed kick_left13.csv.csv to kick_left13.csv\n",
      "Renamed kick_left14.csv.csv to kick_left14.csv\n",
      "Renamed kick_left15.csv.csv to kick_left15.csv\n",
      "Renamed kick_left2.csv.csv to kick_left2.csv\n",
      "Renamed kick_left3.csv.csv to kick_left3.csv\n",
      "Renamed kick_left4.csv.csv to kick_left4.csv\n",
      "Renamed kick_left5.csv.csv to kick_left5.csv\n",
      "Renamed kick_left6.csv.csv to kick_left6.csv\n",
      "Renamed kick_left7.csv.csv to kick_left7.csv\n",
      "Renamed kick_left8.csv.csv to kick_left8.csv\n",
      "Renamed kick_left9.csv.csv to kick_left9.csv\n",
      "Renamed kick_right1.csv.csv to kick_right1.csv\n",
      "Renamed kick_right10.csv.csv to kick_right10.csv\n",
      "Renamed kick_right11.csv.csv to kick_right11.csv\n",
      "Renamed kick_right12.csv.csv to kick_right12.csv\n",
      "Renamed kick_right13.csv.csv to kick_right13.csv\n",
      "Renamed kick_right14.csv.csv to kick_right14.csv\n",
      "Renamed kick_right15.csv.csv to kick_right15.csv\n",
      "Renamed kick_right2.csv.csv to kick_right2.csv\n",
      "Renamed kick_right3.csv.csv to kick_right3.csv\n",
      "Renamed kick_right4.csv.csv to kick_right4.csv\n",
      "Renamed kick_right5.csv.csv to kick_right5.csv\n",
      "Renamed kick_right6.csv.csv to kick_right6.csv\n",
      "Renamed kick_right7.csv.csv to kick_right7.csv\n",
      "Renamed kick_right8.csv.csv to kick_right8.csv\n",
      "Renamed kick_right9.csv.csv to kick_right9.csv\n",
      "Renamed punch16a.csv.csv to punch16a.csv\n",
      "Renamed punch16b.csv.csv to punch16b.csv\n",
      "Renamed punch17a.csv.csv to punch17a.csv\n",
      "Renamed punch17b.csv.csv to punch17b.csv\n",
      "Renamed punch18a.csv.csv to punch18a.csv\n",
      "Renamed punch18b.csv.csv to punch18b.csv\n",
      "Renamed punch19a.csv.csv to punch19a.csv\n",
      "Renamed punch19b.csv.csv to punch19b.csv\n",
      "Renamed punch20.csv.csv to punch20.csv\n",
      "Renamed punch20b.csv.csv to punch20b.csv\n",
      "Renamed punch21a.csv.csv to punch21a.csv\n",
      "Renamed punch21b.csv.csv to punch21b.csv\n",
      "Renamed punch22a.csv.csv to punch22a.csv\n",
      "Renamed punch22b.csv.csv to punch22b.csv\n",
      "Renamed punch23a.csv.csv to punch23a.csv\n",
      "Renamed punch23b.csv.csv to punch23b.csv\n",
      "Renamed punch24a.csv.csv to punch24a.csv\n",
      "Renamed punch24b.csv.csv to punch24b.csv\n",
      "Renamed punch25a.csv.csv to punch25a.csv\n",
      "Renamed punch25b.csv.csv to punch25b.csv\n",
      "Renamed punch26a.csv.csv to punch26a.csv\n",
      "Renamed punch26b.csv.csv to punch26b.csv\n",
      "Renamed punch27a.csv.csv to punch27a.csv\n",
      "Renamed punch27b.csv.csv to punch27b.csv\n",
      "Renamed punch28a.csv.csv to punch28a.csv\n",
      "Renamed punch28b.csv.csv to punch28b.csv\n",
      "Renamed punch29a.csv.csv to punch29a.csv\n",
      "Renamed punch29b.csv.csv to punch29b.csv\n",
      "Renamed punch30a.csv.csv to punch30a.csv\n",
      "Renamed punch30b.csv.csv to punch30b.csv\n",
      "Renamed punch_left1.csv.csv to punch_left1.csv\n",
      "Renamed punch_left10.csv.csv to punch_left10.csv\n",
      "Renamed punch_left11.csv.csv to punch_left11.csv\n",
      "Renamed punch_left12.csv.csv to punch_left12.csv\n",
      "Renamed punch_left13.csv.csv to punch_left13.csv\n",
      "Renamed punch_left14.csv.csv to punch_left14.csv\n",
      "Renamed punch_left15.csv.csv to punch_left15.csv\n",
      "Renamed punch_left2.csv.csv to punch_left2.csv\n",
      "Renamed punch_left3.csv.csv to punch_left3.csv\n",
      "Renamed punch_left4.csv.csv to punch_left4.csv\n",
      "Renamed punch_left5.csv.csv to punch_left5.csv\n",
      "Renamed punch_left6.csv.csv to punch_left6.csv\n",
      "Renamed punch_left7.csv.csv to punch_left7.csv\n",
      "Renamed punch_left8.csv.csv to punch_left8.csv\n",
      "Renamed punch_left9.csv.csv to punch_left9.csv\n",
      "Renamed punch_right1.csv.csv to punch_right1.csv\n",
      "Renamed punch_right10.csv.csv to punch_right10.csv\n",
      "Renamed punch_right11.csv.csv to punch_right11.csv\n",
      "Renamed punch_right12.csv.csv to punch_right12.csv\n",
      "Renamed punch_right13.csv.csv to punch_right13.csv\n",
      "Renamed punch_right14.csv.csv to punch_right14.csv\n",
      "Renamed punch_right15.csv.csv to punch_right15.csv\n",
      "Renamed punch_right2.csv.csv to punch_right2.csv\n",
      "Renamed punch_right3.csv.csv to punch_right3.csv\n",
      "Renamed punch_right4.csv.csv to punch_right4.csv\n",
      "Renamed punch_right5.csv.csv to punch_right5.csv\n",
      "Renamed punch_right6.csv.csv to punch_right6.csv\n",
      "Renamed punch_right7.csv.csv to punch_right7.csv\n",
      "Renamed punch_right8.csv.csv to punch_right8.csv\n",
      "Renamed punch_right9.csv.csv to punch_right9.csv\n",
      "Renamed block1.csv.csv to block1.csv\n",
      "Renamed block10.csv.csv to block10.csv\n",
      "Renamed block11.csv.csv to block11.csv\n",
      "Renamed block12.csv.csv to block12.csv\n",
      "Renamed block13.csv.csv to block13.csv\n",
      "Renamed block14.csv.csv to block14.csv\n",
      "Renamed block15.csv.csv to block15.csv\n",
      "Renamed block16.csv.csv to block16.csv\n",
      "Renamed block17.csv.csv to block17.csv\n",
      "Renamed block18.csv.csv to block18.csv\n",
      "Renamed block19.csv.csv to block19.csv\n",
      "Renamed block2.csv.csv to block2.csv\n",
      "Renamed block20.csv.csv to block20.csv\n",
      "Renamed block21.csv.csv to block21.csv\n",
      "Renamed block22.csv.csv to block22.csv\n",
      "Renamed block23.csv.csv to block23.csv\n",
      "Renamed block24.csv.csv to block24.csv\n",
      "Renamed block25.csv.csv to block25.csv\n",
      "Renamed block26.csv.csv to block26.csv\n",
      "Renamed block27.csv.csv to block27.csv\n",
      "Renamed block28.csv.csv to block28.csv\n",
      "Renamed block29.csv.csv to block29.csv\n",
      "Renamed block3.csv.csv to block3.csv\n",
      "Renamed block30.csv.csv to block30.csv\n",
      "Renamed block4.csv.csv to block4.csv\n",
      "Renamed block5.csv.csv to block5.csv\n",
      "Renamed block6.csv.csv to block6.csv\n",
      "Renamed block7.csv.csv to block7.csv\n",
      "Renamed block8.csv.csv to block8.csv\n",
      "Renamed block9.csv.csv to block9.csv\n",
      "Renamed idle1.csv.csv to idle1.csv\n",
      "Renamed idle10.csv.csv to idle10.csv\n",
      "Renamed idle11.csv.csv to idle11.csv\n",
      "Renamed idle12.csv.csv to idle12.csv\n",
      "Renamed idle13.csv.csv to idle13.csv\n",
      "Renamed idle14.csv.csv to idle14.csv\n",
      "Renamed idle15.csv.csv to idle15.csv\n",
      "Renamed idle16.csv.csv to idle16.csv\n",
      "Renamed idle17.csv.csv to idle17.csv\n",
      "Renamed idle18.csv.csv to idle18.csv\n",
      "Renamed idle19.csv.csv to idle19.csv\n",
      "Renamed idle2.csv.csv to idle2.csv\n",
      "Renamed idle20.csv.csv to idle20.csv\n",
      "Renamed idle21.csv.csv to idle21.csv\n",
      "Renamed idle22.csv.csv to idle22.csv\n",
      "Renamed idle23.csv.csv to idle23.csv\n",
      "Renamed idle24.csv.csv to idle24.csv\n",
      "Renamed idle25.csv.csv to idle25.csv\n",
      "Renamed idle26.csv.csv to idle26.csv\n",
      "Renamed idle27.csv.csv to idle27.csv\n",
      "Renamed idle28.csv.csv to idle28.csv\n",
      "Renamed idle29.csv.csv to idle29.csv\n",
      "Renamed idle3.csv.csv to idle3.csv\n",
      "Renamed idle30.csv.csv to idle30.csv\n",
      "Renamed idle4.csv.csv to idle4.csv\n",
      "Renamed idle5.csv.csv to idle5.csv\n",
      "Renamed idle6.csv.csv to idle6.csv\n",
      "Renamed idle7.csv.csv to idle7.csv\n",
      "Renamed idle8.csv.csv to idle8.csv\n",
      "Renamed idle9.csv.csv to idle9.csv\n"
     ]
    }
   ],
   "source": [
    "for class_name in CLASSES_LIST:        \n",
    "    # Get list of csv files for each class\n",
    "    files_list = os.listdir(os.path.join(OUTPUT_DIR, class_name))    \n",
    "    for filename in files_list:\n",
    "        if filename.endswith('.csv.csv'):\n",
    "            folder_name = os.path.join(OUTPUT_DIR,class_name)\n",
    "            # Construct the new filename by removing the extra .csv\n",
    "            new_filename = os.path.join(folder_name, filename[:-4])\n",
    "            # Rename the file\n",
    "            os.rename(os.path.join(folder_name, filename), new_filename)\n",
    "            print(f'Renamed {filename} to {filename[:-4]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
